{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _import modules:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# enable In-Line MatPlotLib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import:\n",
    "from __future__ import division, print_function\n",
    "from matplotlib.pyplot import figure, legend, plot, title\n",
    "from multiprocessing import cpu_count\n",
    "from numpy import exp, float, int, linspace, log, nan, sqrt\n",
    "from os import system\n",
    "from os.path import join\n",
    "from pandas import Categorical, read_csv\n",
    "from random import seed\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "system('pip install --upgrade git+git://GitHub.com/ChicagoBoothML/Helpy --no-dependencies')\n",
    "from ChicagoBoothML_Helpy.EvaluationMetrics import bin_classif_eval\n",
    "from ChicagoBoothML_Helpy.Print import printflush\n",
    "\n",
    "RANDOM_SEED = 99\n",
    "seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import Tabloid Marketing data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase</th>\n",
       "      <th>nTab</th>\n",
       "      <th>moCbook</th>\n",
       "      <th>iRecMer1</th>\n",
       "      <th>llDol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>19.218130</td>\n",
       "      <td>0.049461</td>\n",
       "      <td>3.893452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.119167</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.105900</td>\n",
       "      <td>5.153465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.028096</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.373772</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43.101180</td>\n",
       "      <td>0.559148</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.615696</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.156552</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.398221</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.309224</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.259196</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.318944</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.177555</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>7.522996</td>\n",
       "      <td>0.591757</td>\n",
       "      <td>3.691127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.051294</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.038268</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9976</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9977</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.022441</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9981</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.044345</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9982</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9983</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6.997372</td>\n",
       "      <td>0.297150</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.044934</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.028841</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.236998</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.040890</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>34.198420</td>\n",
       "      <td>0.028410</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>22.240470</td>\n",
       "      <td>0.373772</td>\n",
       "      <td>4.121635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>3.808660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.383182</td>\n",
       "      <td>-2.302585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     purchase  nTab    moCbook  iRecMer1     llDol\n",
       "0           0     0  50.000000  0.019608 -2.302585\n",
       "1           1     4  19.218130  0.049461  3.893452\n",
       "2           0     1  50.000000  0.119167 -2.302585\n",
       "3           0     1  50.000000  0.019608 -2.302585\n",
       "4           0     0  50.000000  0.019608 -2.302585\n",
       "5           0    10  50.000000  0.105900  5.153465\n",
       "6           0     0  50.000000  0.028096 -2.302585\n",
       "7           0     0  50.000000  0.019608 -2.302585\n",
       "8           0     0  50.000000  0.373772 -2.302585\n",
       "9           0     0  50.000000  0.019608 -2.302585\n",
       "10          0     1  43.101180  0.559148 -2.302585\n",
       "11          0     0  50.000000  0.019608 -2.302585\n",
       "12          0     1  50.000000  0.615696 -2.302585\n",
       "13          0     1  50.000000  0.156552 -2.302585\n",
       "14          0     4  50.000000  0.398221 -2.302585\n",
       "15          0     0  50.000000  0.031793 -2.302585\n",
       "16          0     5  50.000000  0.070391 -2.302585\n",
       "17          0     0  50.000000  0.019608 -2.302585\n",
       "18          0     0  50.000000  0.309224 -2.302585\n",
       "19          0     0  50.000000  0.019608 -2.302585\n",
       "20          0     0  50.000000  0.259196 -2.302585\n",
       "21          0     0  50.000000  0.318944 -2.302585\n",
       "22          0     0  50.000000  0.019608 -2.302585\n",
       "23          0     0  50.000000  0.019608 -2.302585\n",
       "24          0     3  50.000000  0.019608 -2.302585\n",
       "25          0     0  50.000000  0.019608 -2.302585\n",
       "26          0     0  50.000000  0.019608 -2.302585\n",
       "27          0     0  50.000000  0.058377 -2.302585\n",
       "28          0     0  50.000000  0.177555 -2.302585\n",
       "29          0     0  50.000000  0.019608 -2.302585\n",
       "...       ...   ...        ...       ...       ...\n",
       "9970        0     0  50.000000  0.019608 -2.302585\n",
       "9971        0     8   7.522996  0.591757  3.691127\n",
       "9972        0     0  50.000000  0.019608 -2.302585\n",
       "9973        0     3  50.000000  0.019608 -2.302585\n",
       "9974        0     0  50.000000  0.051294 -2.302585\n",
       "9975        0     1  50.000000  0.038268 -2.302585\n",
       "9976        0     0  50.000000  0.019608 -2.302585\n",
       "9977        0     1  50.000000  0.019608 -2.302585\n",
       "9978        0     0  50.000000  0.022441 -2.302585\n",
       "9979        0     2  50.000000  0.019608 -2.302585\n",
       "9980        0     0  50.000000  0.019608 -2.302585\n",
       "9981        0     2  50.000000  0.044345 -2.302585\n",
       "9982        0     0  50.000000  0.019608 -2.302585\n",
       "9983        0     0  50.000000  0.019608 -2.302585\n",
       "9984        1    14   6.997372  0.297150 -2.302585\n",
       "9985        0     0  50.000000  0.019608 -2.302585\n",
       "9986        0     0  50.000000  0.019608 -2.302585\n",
       "9987        0     0  50.000000  0.019608 -2.302585\n",
       "9988        0     0  50.000000  0.019608 -2.302585\n",
       "9989        0     2  50.000000  0.044934 -2.302585\n",
       "9990        0     0  50.000000  0.028841 -2.302585\n",
       "9991        0     0  50.000000  0.236998 -2.302585\n",
       "9992        0     0  50.000000  0.040890 -2.302585\n",
       "9993        0     0  50.000000  0.019608 -2.302585\n",
       "9994        0     2  34.198420  0.028410 -2.302585\n",
       "9995        0     0  50.000000  0.019608 -2.302585\n",
       "9996        0     0  50.000000  0.019608 -2.302585\n",
       "9997        1    10  22.240470  0.373772  4.121635\n",
       "9998        0     2  50.000000  0.019608  3.808660\n",
       "9999        0     0  50.000000  0.383182 -2.302585\n",
       "\n",
       "[10000 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read Credit Scoring data into data frame\n",
    "y_var_name = 'purchase'\n",
    "X_var_names = [\n",
    "    'nTab',\n",
    "    'moCbook',\n",
    "    'iRecMer1',\n",
    "    'llDol']\n",
    "column_classes = dict(\n",
    "    purchase=int,\n",
    "    nTab=float,\n",
    "    moCbook=float,\n",
    "    iRecMer1=float,\n",
    "    llDol=float)\n",
    "\n",
    "data_repo_raw_path = 'https://raw.githubusercontent.com/ChicagoBoothML/DATA__Tabloid/master'\n",
    "tabloid_train = read_csv(\n",
    "    join(data_repo_raw_path, 'Tabloid_train.csv').replace('\\\\', '/'),\n",
    "    dtype=column_classes)\n",
    "\n",
    "tabloid_train.purchase = Categorical(tabloid_train.purchase)\n",
    "\n",
    "nb_train_samples = len(tabloid)\n",
    "\n",
    "tabloid_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to sanity-check, the classes of the variables are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "purchase: category\n",
      "nTab: float64\n",
      "moCbook: float64\n",
      "iRecMer1: float64\n",
      "llDol: float64\n"
     ]
    }
   ],
   "source": [
    "#cs.apply(lambda col: col.dtype)\n",
    "\n",
    "for col_name in tabloid_train:\n",
    "    printflush('%s: %s' %(col_name, tabloid_train[col_name].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The incidence of responsiveness to marketing in the Training set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0258"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(tabloid_train.purchase) / nb_train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this creates a \"**skewed classes**\" problem: one of the classes of cases (here the \"delinquent\" class) is significantly rarer than the other.\n",
    "\n",
    "_(**note**: in more extreme cases where one class is much, much rarer than the other to the order of 1000 or 10,000 times, our model fitting procedures would need to be tweaked; but this case is not so extreme)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of missing data points per column in the Training set are as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purchase    0\n",
       "nTab        0\n",
       "moCbook     0\n",
       "iRecMer1    0\n",
       "llDol       0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabloid_train.isnull().sum() / len(tabloid_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now split a bit of data from the Training set as a Validation set for the purpose of estimating OOS performance metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tabloid_train, tabloid_valid = train_test_split(\n",
    "    tabloid_train,\n",
    "    train_size=2. / 3.,\n",
    "    random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Just to sanity-check that the data sets have been split representatively: the delinquency incidences in the Training and Validation sets are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6666 obs: 0.025503 responsive\n",
      "3334 obs: 0.026395 responsive\n"
     ]
    }
   ],
   "source": [
    "for data_set in (tabloid_train, tabloid_valid):\n",
    "    printflush('%i obs: %f responsive' %(len(data_set), sum(data_set.purchase) / len(data_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models\n",
    "\n",
    "Let's train 3 types of classification models: a Random Forest, a Boosted Trees model and a Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "            min_samples_leaf=30, min_samples_split=60,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=6,\n",
       "            oob_score=True, random_state=99, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 1000\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=B,\n",
    "    criterion='entropy',\n",
    "    max_depth=None,   # expand until all leaves are pure or contain < MIN_SAMPLES_SPLIT samples\n",
    "    min_samples_split=60,\n",
    "    min_samples_leaf=30,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_features=None,   # number of features to consider when looking for the best split; None: max_features=n_features\n",
    "    max_leaf_nodes=None,   # None: unlimited number of leaf nodes\n",
    "    bootstrap=True,\n",
    "    oob_score=True,   # estimate Out-of-Bag Cross Entropy\n",
    "    n_jobs=cpu_count() - 2,   # paralellize over all CPU cores but 2\n",
    "    class_weight=None,    # our classes are skewed, but but too skewed\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=0,\n",
    "    warm_start=False)\n",
    "\n",
    "rf_model.fit(X=tabloid_train[X_var_names], y=tabloid_train.purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.01, loss='deviance',\n",
       "              max_depth=10, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=60, min_samples_split=120,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "              random_state=99, subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 1000\n",
    "\n",
    "boost_model = GradientBoostingClassifier(\n",
    "    n_estimators=B,\n",
    "    loss='deviance',   # a.k.a Cross Entropy in Classification\n",
    "    learning_rate=.01,   # shrinkage parameter\n",
    "    subsample=1.,\n",
    "    min_samples_split=120,\n",
    "    min_samples_leaf=60,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=10,   # maximum tree depth / number of levels of interaction\n",
    "    init=None,\n",
    "    random_state=RANDOM_SEED,\n",
    "    max_features=None,   # number of features to consider when looking for the best split; None: max_features=n_features\n",
    "    verbose=0,\n",
    "    max_leaf_nodes=None,   # None: unlimited number of leaf nodes\n",
    "    warm_start=False)\n",
    "\n",
    "boost_model.fit(X=tabloid_train[X_var_names], y=tabloid_train.purchase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "          multi_class='multinomial', penalty='l2', random_state=99,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(\n",
    "    penalty='l2',\n",
    "    dual=False,\n",
    "    tol=0.0001,\n",
    "    C=1e3,   # large C so as NOT to regularize too strongly\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=1.,\n",
    "    class_weight=None,\n",
    "    random_state=RANDOM_SEED,\n",
    "    solver='lbfgs',\n",
    "    max_iter=100,\n",
    "    multi_class='multinomial',\n",
    "    verbose=0)\n",
    "\n",
    "X_standard_scaler = StandardScaler()\n",
    "X_standard_scaler.fit(tabloid_train[X_var_names])\n",
    "log_reg_model.fit(\n",
    "    X=X_standard_scaler.transform(tabloid_train[X_var_names]),\n",
    "    y=tabloid_train.purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now evaluate the OOS performances of these 3 models on the Validation set to select a model we think is best:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_prob = 1e-6\n",
    "high_prob = 1 - low_prob\n",
    "log_low_prob = log(low_prob)\n",
    "log_high_prob = log(high_prob)\n",
    "log_prob_thresholds = linspace(start=log_low_prob, stop=log_high_prob, num=100)\n",
    "prob_thresholds = exp(log_prob_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rf_pred_probs = rf_model.predict_proba(X=tabloid_valid[X_var_names])\n",
    "rf_oos_performance = bin_classif_eval(\n",
    "    rf_pred_probs[:, 1], tabloid_valid.purchase,\n",
    "    pos_cat=1, thresholds=prob_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "boost_pred_probs = boost_model.predict_proba(X=tabloid_valid[X_var_names])\n",
    "boost_oos_performance = bin_classif_eval(\n",
    "    boost_pred_probs[:, 1], tabloid_valid.purchase,\n",
    "    pos_cat=1, thresholds=prob_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_reg_pred_probs = log_reg_model.predict_proba(\n",
    "    X=X_standard_scaler.transform(tabloid_valid[X_var_names]))\n",
    "log_reg_oos_performance = bin_classif_eval(\n",
    "    log_reg_pred_probs[:, 1], tabloid_valid.purchase,\n",
    "    pos_cat=1, thresholds=prob_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x105ff4ed0>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAF6CAYAAADMN/v3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1JhFREQCiBqziIhIAPn/Dmsl9Ca+YQMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10f3bd250>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(figsize=(8, 6))\n",
    "plot(\n",
    "    [0, 1], [0, 1],\n",
    "    linestyle='dotted')\n",
    "plot(\n",
    "    1 - rf_oos_performance.specificity,\n",
    "    rf_oos_performance.recall,\n",
    "    label='Random Forest')\n",
    "plot(\n",
    "    1 - boost_oos_performance.specificity,\n",
    "    boost_oos_performance.recall,\n",
    "    label='Boosted Trees')\n",
    "plot(\n",
    "    1 - log_reg_oos_performance.specificity,\n",
    "    log_reg_oos_performance.recall,\n",
    "    label='Logistic Regression')\n",
    "title('ROC Curves (Validation Data)')\n",
    "legend(loc='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We see that with suitable data, Logistic Regression is right up there with Random Forest and Boosted Trees in terms of OOS performance! Let's choose the Logistic Regression model for evaluation on the Test set.\n",
    "\n",
    "We now need to pick a decision threshold for the Boosted Trees model. If we are to be really rigorous, we'll need to inject some business knowledge, e.g. balancing the costs opportunity costs of missing out lucrative customers and the costs of targeted marketing. Here, to make life simple, we'll pick a subjective threshold that enables us to anticipate **80%** of the responsive cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10722663230387419"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_threshold = .8\n",
    "idx = next(i for i in range(100) if log_reg_oos_performance.recall[i] <= recall_threshold) - 1\n",
    "selected_prob_threshold = prob_thresholds[idx]\n",
    "selected_prob_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OOS performance of the Logistic Regression algorithm at this threshold is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "threshold      0.107227\n",
       "accuracy       0.637972\n",
       "recall         0.818182\n",
       "specificity    0.633087\n",
       "precision      0.057007\n",
       "f1_score       0.106588\n",
       "deviance       0.346598\n",
       "Name: 83, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_oos_performance.iloc[idx, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is trade-off: the precision of the model at this sensitivity threshold is rather low, meaning that there'll be many false positives, i.e. we may be spamming and annoying lots of people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Performance of Selected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabloid_test = read_csv(\n",
    "    join(data_repo_raw_path, 'Tabloid_test.csv').replace('\\\\', '/'),\n",
    "    dtype=column_classes)\n",
    "\n",
    "tabloid_test.purchase = Categorical(tabloid_test.purchase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The expected performance of the model on the Test set at the decision threshold determined above is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.64080000000000004,\n",
       " 'deviance': 0.3318770258807799,\n",
       " 'f1_score': 0.08832487309644671,\n",
       " 'precision': 0.046824542518837463,\n",
       " 'recall': 0.7767857142857143,\n",
       " 'specificity': 0.63768412438625199}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_pred_probs = log_reg_model.predict_proba(\n",
    "    X=X_standard_scaler.transform(tabloid_test[X_var_names]))\n",
    "log_reg_oos_performance = bin_classif_eval(\n",
    "    log_reg_pred_probs[:, 1], tabloid_test.purchase,\n",
    "    pos_cat=1, thresholds=selected_prob_threshold)\n",
    "log_reg_oos_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the Test performance is broadly similar to what we've estimated from the Validation set. The selected model works as expected: we'll get responsiveness from >70% of the targeted customers, but our reputation as a spamming organization will also be reinforced..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
